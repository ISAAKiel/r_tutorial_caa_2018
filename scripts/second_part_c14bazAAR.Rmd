---
title: "CAA2018 Tutorial Second Part"
author: "Clemens Schmid"
date: "2 März 2018"
output: 
  html_document:
    keep_md: true
    toc: TRUE
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = F)
```

```{r, results='hide', message=FALSE, warning=FALSE}
library(tidyverse)
library(magrittr)
library(mapview)
library(sp)
library(sf)
# might be necessary to detach rcarbon first due to 'calibrate()' function
# detach('package:rcarbon')
library(c14bazAAR)
```

## c14bazAAR

c14bazAAR is a R package to download and prepare bulk c14 date collections.

### Why is this useful?

#### Radiocarbon dates

- c14 dates are fairly standardised (a pillar of stability in the Bad Data of archaeology)
- c14 dates have high resolution temporal and spatial information (they can be linked to all kind of data -- archaeology, climatology, genetics, linguistics...) 
- c14 dates are linked to distinct events in human history (they tell stories)

#### R package?

- User perspective
    - access many highly different databases with one interface
    - reproducibility with scripted data selection
    - standard data structures for direct access to powerful R tools (tidyverse)
- Developer perspective
    - Open Source: examine & improve the implementation and adjust everything for your needs
    - simple parser development framework to add further databases
    - embed bulk c14 dates into your own application

### Open Archives

- **14SEA** 14C database for Southeast Europe and Anatolia (10,000–3000 calBC).
- **aDRAC** Archives des datations radiocarbone d'Afrique centrale by Dirk Seidensticker.
- **AustArc** A Database of 14C and Luminescence Ages from Archaeological Sites in Australia by Alan N. Williams, Sean Ulm, Mike Smith, Jill Reid
- **CALPAL** Radiocarbon Database of the CalPal software package by Bernhard Weninger. See nevrome/CalPal-Database for an interface.
- **CONTEXT** Collection of radiocarbon dates from sites in the Near East and neighboring regions (20.000 - 5.000 calBC) by Utz Böhner and Daniel Schyle.
- **EUROEVOL** Cultural Evolution of Neolithic Europe Dataset by Katie Manning, Sue Colledge, Enrico Crema, Stephen Shennan and Adrian Timpson.
- **CARD Upload Template - KITE East Africa v2.1** Radiocarbon dates from eastern Africa in the CARD2.0 format by Colin Courtney Mustaphi, Rob Marchant
- **RADON** Central European and Scandinavian database of 14C dates for the Neolithic and Early Bronze Age by Dirk Raetzel-Fabian, Martin Furholt, Martin Hinz, Johannes Müller, Christoph Rinne, Karl-Göran Sjögren und Hans-Peter Wotzka.
- **RADON-B** Database for European 14C dates for the Bronze and Early Iron Age by Jutta Kneisel, Martin Hinz, Christoph Rinne.
- **...**

If you know more, add them in [this](https://github.com/ISAAKiel/c14bazAAR/issues/2) issue or join the development of c14bazAAR and start an own pull request.

### Let's get some data

c14bazAAR offers an individual parser function for every source database.

```{r}
c14bazAAR:::get_all_parser_functions()[1:2]
```

We can use one of them to download one specific collection.

```{r}
get_AustArch()
```

Or two or more to merge them afterwards. 

```{r}
adrac <- get_aDRAC()
radonb <- get_RADONB()

fuse(adrac, radonb)
```

We can even download all dates from all databases.

```{r, results = 'hide'}
all_dates <- get_all_dates()
```

### An own data structure: the c14_date_list

A c14_date_list is a modified tibble (which is a modified data.frame). It's a S3 class with a custom print function.

```{r}
class(all_dates)
```

We can apply every operation to a c14_date_list that can also be applied to a data.frame, but most functions in c14bazAAR require a c14_date_list. If we apply functions that give back a data.frame or a tibble, then we lose the class tag. We'll see the consequences of this later.

```{r}
?c14_date_list
```

The c14_date_list has a defined set of variables (columns) that are arranged in a defined order. There's no explicit constructor function, but you can use `as.c14_date_list()` to create a c14_date_list from a data.frame or a tibble. `as.c14_date_list()` triggers `enforce_types()`, `order_variables()` and `c14bazAAR:::clean_latlon()`.

```{r}
candidate <- data.frame(
  c14std = c(30, "20"),
  country = c("Germany", "Austria"),
  c14age = c(3000, 2500),
  stringsAsFactors = F
)

as.c14_date_list(candidate)
```

The distinct set of variables and how they relate to the variables in the source databases are documented [here](https://github.com/ISAAKiel/c14bazAAR/blob/master/data-raw/variable_reference.csv). 

```{r}
variable_reference
```

### Enhance your c14_date_list: core functions of c14bazAAR

c14bazAAR 1.0.0 offers functions to cover four domains:

- calibration
- material classification
- fixing country names
- marking duplicates

All of these contain certain challenges, mostly caused by the low data quality of the source databases. 

#### calibration

The c14 age is not the correct absolute age of a date. To correct the age value we have to apply ^14^C calibration. c14bazAAR offers a method to individually calibrate all dates in a c14_date_list. The actual calibration is done by `Bchron::BchronCalibrate()`.

```{r, results = 'hide'}
dates_selection <- as.c14_date_list(all_dates[10000:10100,])

calibrate(dates_selection)
```

```{r}
dates_selection
```

Unfortunately the result of calibration is per definition not a simple number but a probability distribution. To store this information in a data.frame in R we have to rely on list columns. 

`calibrate` provides two types of output: 

- calprobdistr: A full representation of the probability per year for all years above a certain threshold.     
- calrange: Only the age ranges of a defined sigma level.  

```{r, results = 'hide'}
calibrated <- calibrate(
  dates_selection,
  choices = c("calprobdistr", "calrange"),
  sigma = 2
)
```

```{r}
head(calibrated$calprobdistr[[1]])
head(calibrated$calrange)
```

The necessity for list columns makes working with this results more challenging. For example: How do we find the dates of a certain timeframe (4000 - 4500 calBP)?

```{r}
dates_4000_4500 <- calibrated %>%
  dplyr::select(labnr, calrange) %>%
  tidyr::unnest() %>%
  dplyr::filter(
    from >= 4000 & from <= 4500 |
      to >= 4000 & to <= 4500
  ) %$%
  labnr %>%
  unique

calibrated[calibrated$labnr %in% dates_4000_4500, ]
```

#### material classification

Almost all databases have information about the sample material, but the terminology isn't standardized (across and within databases). 

```{r}
calpal <- get_CalPal() %>% 
  dplyr::sample_n(1000) %>% 
  as.c14_date_list()

unique(calpal$material)

ggplot(calpal, aes(x = material)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

The c14bazAAR function `classify_material()` applies a manually curated thesaurus to unify certain termes to make data selection less tedious. 

```{r, message=FALSE}
calpal_material <- classify_material(calpal)

ggplot(calpal_material, aes(x = material_thes)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

The thesaurus is prepared for all entries in all databases that are currently accessible with c14bazAAR. But as soon as new information is entered into the source databases or new source databases are added it needs servicing.

```{r}
material_thesaurus
```

#### better country information

Selection by country is a valuable mean of filtering especially for dates without coordinates. Unfortunately the country information in the source databases is not very reliable and the country names are not standardized across (and sometimes even within) databases.

The consequence are wrong filtering results. That's especially annoying for the neolithicRC webapp.

```{r}
germany <- all_dates %>%
  dplyr::filter(country == "Germany") %>%
  dplyr::sample_n(100) %>%
  as.c14_date_list()
```

```{r, eval = FALSE}
germany %>% as.sf %>% mapview()
```

To fix this, we can apply a series of functions: `determine_country_by_coordinates()`, `standardize_country_name()` and `finalize_country_name()`.

##### country by coordinates

`determine_country_by_coordinates()` determines the country with a spatial join to a set of country polygons (`rworldxtra::countriesHigh`). Points that are not within a country polygon are matched to the closest one.

```{r}
utils::data("countriesHigh", package = "rworldxtra", envir = environment())

plot(countriesHigh)

germany <- germany %>% determine_country_by_coordinate()

germany_coords <- germany %>%
  dplyr::filter(country_coord == "Germany") %>%
  as.c14_date_list()
```

```{r, eval = FALSE}
germany_coords %>% as.sf %>% mapview()
```

##### fixing country names

`standardize_country_name()` fixes country names by comparing the values in the country column to a general list of country identifiers (`countrycode::codelist`) and a small manually curated thesaurus for special cases. 

```{r}
head(countrycode::codelist[,c(5, 10, 20)])
```

```{r}
country_thesaurus
```

```{r, message = FALSE}
adrac %>% 
  standardize_country_name() %>% 
  dplyr::select(country, country_thes) %>% 
  unique
```

`finalize_country_name()` calls both previous functions and selects a final country name with the following selection hierarchy: country_coord > country_thes > country.

#### marking and removing duplicates

Combining different source databases causes a lot of dates to appear more than once in the result selection. Also some databases already contain duplicates due to bad maintenance.

```{r}
duplicate_selection <- all_dates %>% dplyr::sample_n(5000)

duplicate_selection %>%
  dplyr::group_by(labnr) %>%
  dplyr::summarise(n = n()) %$% 
  table(n)
```

`mark_duplicates` searches for duplicates in labnrs and marks duplicate groups.

```{r, results = 'hide'}
duplicate_selection <- duplicate_selection %>%
  as.c14_date_list() %>%
  mark_duplicates()
```

```{r}
duplicate_selection$duplicate_group %>% unique

duplicate_selection %>%
  dplyr::filter(duplicate_group == 30)
```

Unfortunately there is no good way to merge dates automatically. Somebody has to check the information and make a decision for one entry or the other based on their research question.

c14bazAAR provides the function `remove_duplicates()` (aka "The annihilator"), but it removes also a lot of valuable information.

```{r}
duplicates_removed <- duplicate_selection %>% remove_duplicates()

duplicates_removed %>% 
  dplyr::filter(duplicate_group == 30)

duplicates_removed %>% 
  dplyr::filter(duplicate_group == 30) %$%
  duplicate_remove_log
```

Another way to get a first understanding on the data without the duplicates is to just keep the first date in every duplicate group.

```{r}
duplicate_selection[!is.na(duplicate_selection$duplicate_group), ] %>%
  dplyr::group_by(duplicate_group) %>%
  dplyr::do(head(., n = 1)) %>% 
  dplyr::ungroup()
```

### Final challenge: Preparing a dataset (for Martin)

```{r eval = FALSE}
#### download shapefile from Baden-Württemberg ####

# create a tempfile
temp <- tempfile()

# download archive with shapefile
utils::download.file(
  "https://www.lgl-bw.de/lgl-internet/web/sites/default/de/07_Produkte_und_Dienstleistungen/Open_Data_Initiative/Galerien/Dokumente/AX_Gebiet_Bundesland.zip", 
  temp, 
  quiet = TRUE
)

# unzip archive in tempdir
utils::unzip(
  temp,
  exdir = tempdir()
)

# read shapefile into R
bawue_sf <- st_read(file.path(tempdir(), "AX_Gebiet_Bundesland.shp"))

plot(bawue_sf$geometry)

#### prepare date dataset ####

# reduce date selection (to reduce calculation time)
sw_germany_dates_1 <- all_dates %>%
  dplyr::filter(lat < 50, lat > 47, lon < 11, lon > 7.5)
  
sw_germany_dates_2 <- sw_germany_dates_1 %>%
  as.c14_date_list() %>%
  classify_material() %>%
  dplyr::filter(material_thes != "charcoal", material_thes != "wood")

sw_germany_dates_3 <- sw_germany_dates_2 %>%
  as.c14_date_list() %>%
  determine_country_by_coordinate() %>%
  dplyr::filter(country_coord == "Germany")

sw_germany_dates_4 <- sw_germany_dates_3 %>%
  as.c14_date_list() %>%
  remove_duplicates()
  
# make c14_date_list a sf object and transform coordinates to ETRS89 / UTM zone 32N reference system
sw_germany_dates_sf <- sw_germany_dates_4 %>%
  as.c14_date_list()%>%
  as.sf %>%
  st_transform(crs = 25832)

plot(sw_germany_dates_sf$geom, add = TRUE, col = "black")

#### intersect shape with dates ####

# spatial intersection to find dates within Baden-Württemberg
bawue_dates_sf <- sw_germany_dates_sf %>%
  st_intersection(y = bawue_sf)

plot(bawue_dates_sf$geom, add = TRUE, col = "red")

# transform this sf file to a data.frame
bawue_dates <- bawue_dates_sf
st_geometry(bawue_dates) <- NULL
colnames(bawue_dates) <- gsub("data.", "", colnames(bawue_dates))

#### final selection by timeframe

# calibrate the dates in this selection
bawue_calibrated <- bawue_dates %>%
  as.c14_date_list() %>%
  calibrate(choices = "calprobdistr")

# select dates by timeframe
bawue_final <- bawue_calibrated %>%
  unnest() %>%
  dplyr::filter(
    calage > 2700, calage < 7500
  ) %>%
  dplyr::group_by(labnr) %>%
  dplyr::do(head(., n = 1)) %>% 
  dplyr::ungroup()

#saveRDS(bawue_final, file = "bawue_final.RDS")
```
